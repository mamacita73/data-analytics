{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 02_harmonisierung — Cell 1\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import sys, os, json, re\n",
    "import pandas as pd\n",
    "\n",
    "# --- Projekt-Konfiguration laden (aus 01_import_und_setup erzeugt) ---\n",
    "BASE   = Path.cwd().resolve().parents[0] if Path.cwd().name.lower()==\"notebooks\" else Path.cwd()\n",
    "OUT    = BASE / \"data\" / \"processed\"\n",
    "CONFIG = json.loads((OUT / \"project_config.json\").read_text(encoding=\"utf-8\"))\n",
    "\n",
    "RAW   = Path(CONFIG[\"paths\"][\"raw\"])\n",
    "OUT   = Path(CONFIG[\"paths\"][\"processed\"])\n",
    "FIG   = Path(CONFIG[\"paths\"][\"figures\"])\n",
    "MAP_CSV = Path(CONFIG[\"paths\"][\"mapping_csv\"])\n",
    "KANON = CONFIG[\"kanon\"]\n",
    "\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "FIG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- zu verarbeitende Jahre/Dateien (bei Bedarf hier anpassen) ---\n",
    "YEAR_TO_FILE = {\n",
    "    2021: \"statista_2021.csv\",\n",
    "    2022: \"statista_2022.csv\",\n",
    "    2024: \"statista_2024.csv\",\n",
    "}\n",
    "\n",
    "print(\"Konfiguration geladen.\")\n",
    "print(\"RAW:\", RAW)\n",
    "print(\"OUT:\", OUT)\n",
    "print(\"FIG:\", FIG)\n",
    "print(\"Mapping CSV:\", MAP_CSV)\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 02_harmonisierung — Cell 2\n",
    "# Versuche, Utils aus src/ zu importieren; sonst lokale Fallbacks bereitstellen.\n",
    "try:\n",
    "    sys.path.append(str(BASE / \"src\"))  # erlaubt from utils.* Imports\n",
    "    from utils.io_utils import read_csv_robust, pick_statista_cols, clean_value_col\n",
    "    from utils.text_utils import norm_text\n",
    "    print(\"Utils aus src/ geladen.\")\n",
    "except Exception as e:\n",
    "    print(\"Warnung: Utils nicht gefunden, nutze Fallback-Implementierungen.\", e)\n",
    "\n",
    "    def read_csv_robust(path: Path) -> pd.DataFrame:\n",
    "        encodings = [\"utf-8-sig\", \"cp1252\", \"latin1\"]\n",
    "        last = None\n",
    "        for enc in encodings:\n",
    "            try:\n",
    "                return pd.read_csv(path, encoding=enc, sep=None, engine=\"python\")\n",
    "            except UnicodeDecodeError as ex:\n",
    "                last = ex\n",
    "                continue\n",
    "        return pd.read_csv(path, encoding=\"latin1\", sep=None, engine=\"python\")\n",
    "\n",
    "    def pick_statista_cols(df: pd.DataFrame) -> tuple[str, str | None]:\n",
    "        cat_col = val_col = None\n",
    "        normalized = {str(c).strip().lower(): c for c in df.columns}\n",
    "        for key, c in normalized.items():\n",
    "            if key in {\"category\",\"kategorie\",\"warengruppe\",\"produktkategorie\",\"bereich\"}:\n",
    "                cat_col = c\n",
    "            if key in {\"value\",\"wert\",\"prozent\",\"anteil\",\"share\",\"%\",\"rate\",\"anzahl\"}:\n",
    "                val_col = c\n",
    "        if cat_col is None:\n",
    "            raise ValueError(\"Kategorien-Spalte fehlt (category/kategorie/warengruppe/...).\")\n",
    "        return cat_col, val_col\n",
    "\n",
    "    def clean_value_col(series: pd.Series) -> pd.Series:\n",
    "        return (series.astype(str)\n",
    "                     .str.replace(\"%\",\"\", regex=False)\n",
    "                     .str.replace(\",\",\".\", regex=False)\n",
    "                     .str.strip()\n",
    "                     .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "                     .fillna(0.0))\n",
    "\n",
    "    def norm_text(s: str) -> str:\n",
    "        if pd.isna(s): return \"\"\n",
    "        s = str(s).strip().lower()\n",
    "        s = s.replace(\"&\",\"und\").replace(\"-\",\" \")\n",
    "        s = re.sub(r\"\\s+\",\" \", s)\n",
    "        s = s.replace(\"accressoires\",\"accessoires\").replace(\"hi tech\",\"high tech\")\n",
    "        return s\n"
   ],
   "id": "39590708f175af5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 02_harmonisierung — Cell 3\n",
    "mapping_df = pd.read_csv(MAP_CSV, encoding=\"utf-8\")\n",
    "assert {\"source\",\"source_normalized\",\"kanon\"}.issubset(mapping_df.columns), \"Mapping CSV hat unerwartetes Format.\"\n",
    "\n",
    "# MAP_NORM: normalisierte Quellbegriffe -> KANON\n",
    "MAP_NORM = dict(mapping_df[[\"source_normalized\",\"kanon\"]].values)\n",
    "\n",
    "# Sanity: doppelte Normalisate identifizieren\n",
    "dups = (mapping_df.groupby(\"source_normalized\")\n",
    "                    .size()\n",
    "                    .reset_index(name=\"n\")\n",
    "                    .query(\"n>1\"))\n",
    "if not dups.empty:\n",
    "    display(dups.head())\n",
    "    print(\"Hinweis: Es gibt mehrfach vorkommende normalisierte Keys. Prüfe semantische Duplikate im Mapping.\")\n",
    "else:\n",
    "    print(\"MAP_NORM OK – keine doppelten normalisierten Keys.\")\n"
   ],
   "id": "54a911c82e6e69cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 02_harmonisierung — Cell 4\n",
    "def load_and_harmonize_year(year: int, filename: str,\n",
    "                            raw_dir: Path = RAW,\n",
    "                            map_norm: dict[str,str] = MAP_NORM) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lädt eine Statista-CSV, erkennt Kategorien- und Werte-Spalte, bereinigt Prozentwerte,\n",
    "    mappt Quellkategorien auf KANON und aggregiert Teilkategorien.\n",
    "    Rückgabe: DataFrame mit Spalten [year, Kategorie, value]\n",
    "    \"\"\"\n",
    "    path = raw_dir / filename\n",
    "    df = read_csv_robust(path)\n",
    "\n",
    "    cat_col, val_col = pick_statista_cols(df)\n",
    "    work = df[[cat_col] + ([val_col] if val_col else [])].copy()\n",
    "    work.rename(columns={cat_col: \"source_category\"}, inplace=True)\n",
    "    work[\"value\"] = clean_value_col(work[val_col]) if val_col else 0.0\n",
    "\n",
    "    # Mapping\n",
    "    work[\"Kategorie\"] = work[\"source_category\"].map(lambda x: map_norm.get(norm_text(x), \"IGNORE\"))\n",
    "    before = len(work)\n",
    "    work = work[work[\"Kategorie\"] != \"IGNORE\"].copy()\n",
    "    dropped = before - len(work)\n",
    "\n",
    "    if dropped:\n",
    "        print(f\"[{year}] {dropped} Zeile(n) ohne Mapping entfernt (IGNORE).\")\n",
    "\n",
    "    # Aggregation (z. B. Bekleidung/Schuhe/Accessoires)\n",
    "    out = (work.groupby(\"Kategorie\", as_index=False)[\"value\"].sum()\n",
    "                 .assign(year=year)[[\"year\",\"Kategorie\",\"value\"]])\n",
    "\n",
    "    # Numerik & Bounds\n",
    "    out[\"value\"] = pd.to_numeric(out[\"value\"], errors=\"coerce\").fillna(0.0)\n",
    "    return out\n"
   ],
   "id": "47a29fe1d5fdb34"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 02_harmonisierung — Cell 5\n",
    "frames = []\n",
    "missing_files = []\n",
    "for yr, fname in YEAR_TO_FILE.items():\n",
    "    fpath = RAW / fname\n",
    "    if not fpath.exists():\n",
    "        missing_files.append((yr, fpath))\n",
    "        continue\n",
    "    frames.append(load_and_harmonize_year(yr, fname))\n",
    "\n",
    "if missing_files:\n",
    "    print(\"Warnung: fehlende Dateien:\")\n",
    "    for yr, p in missing_files:\n",
    "        print(f\"  - {yr}: {p}\")\n",
    "\n",
    "assert frames, \"Keine Daten geladen. Prüfe YEAR_TO_FILE und data/raw.\"\n",
    "\n",
    "stat_all = pd.concat(frames, ignore_index=True)\n",
    "# Wide-Format (Kategorien x Jahr)\n",
    "stat_pivot = (stat_all.pivot(index=\"Kategorie\", columns=\"year\", values=\"value\")\n",
    "                       .reindex(KANON)           # fixe Reihenfolge\n",
    "                       .fillna(0.0))\n",
    "\n",
    "display(stat_all.head(10))\n",
    "display(stat_pivot.head(len(KANON)))\n"
   ],
   "id": "c91bd960a1401079"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 02_harmonisierung — Cell 6\n",
    "# 1) Wertebereich 0–100 %\n",
    "if not stat_all[\"value\"].between(0, 100).all():\n",
    "    offenders = stat_all[~stat_all[\"value\"].between(0, 100)].sort_values(\"value\")\n",
    "    display(offenders.head(10))\n",
    "    raise ValueError(\"Es existieren Prozentwerte außerhalb 0–100 %. Quelle prüfen.\")\n",
    "\n",
    "# 2) Duplikate je (year, Kategorie) nach Aggregation?\n",
    "dups = (stat_all.groupby([\"year\",\"Kategorie\"]).size()\n",
    "                  .reset_index(name=\"n\")\n",
    "                  .query(\"n>1\"))\n",
    "if not dups.empty:\n",
    "    display(dups)\n",
    "    raise ValueError(\"Duplikate je (year, Kategorie) nach Aggregation gefunden.\")\n",
    "\n",
    "# 3) Vollständigkeit ggü. KANON (Hinweis, kein harter Fehler)\n",
    "fehlend = set(KANON) - set(stat_pivot.index)\n",
    "if fehlend:\n",
    "    print(\"Hinweis – folgende KANON-Kategorien fehlen in den vorliegenden Daten:\", fehlend)\n",
    "else:\n",
    "    print(\"Alle KANON-Kategorien vorhanden (zumindest als Index).\")\n",
    "\n",
    "print(\"Qualitätschecks erfolgreich.\")\n"
   ],
   "id": "517289ba898b986a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 02_harmonisierung — Cell 7\n",
    "LONG_OUT  = OUT / \"statista_long_2021_2022_2024.csv\"\n",
    "WIDE_OUT  = OUT / \"statista_harmonisiert_2021_2022_2024.csv\"\n",
    "\n",
    "(stat_all.sort_values([\"year\",\"Kategorie\"])\n",
    "         .to_csv(LONG_OUT, index=False, encoding=\"utf-8\"))\n",
    "(stat_pivot.reset_index()\n",
    "          .to_csv(WIDE_OUT, index=False, encoding=\"utf-8\"))\n",
    "\n",
    "print(\"Exportiert:\")\n",
    "print(\" -\", LONG_OUT)\n",
    "print(\" -\", WIDE_OUT)\n",
    "print(\"Weiter mit 30_reporting.ipynb → Abbildungen generieren.\")\n"
   ],
   "id": "25fab017fc42ba3c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
